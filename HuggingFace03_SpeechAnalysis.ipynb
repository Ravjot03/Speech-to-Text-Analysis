{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28OvcgAvBpTn",
    "outputId": "27c702e8-d3e7-4faa-dfbc-47d52c1729d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 55bb623 (https://huggingface.co/facebook/wav2vec2-base-960h).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "transcriber = pipeline(task=\"automatic-speech-recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_eKGGwZB_T6",
    "outputId": "99137684-cff6-44cf-ad6d-6fa9d9499461"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"SOTS LOLE   A MOE WIT OT ACONES TAKING WIT TRUST ME AND TRUST ME I'LL GIV THAT  JUER DOWN IN MY HANDS TO AN THE MAN ON THE TO BOES IN HIMN WE STOT  DOWNS AND OGSING AND LET GO YOU  O LOV ONT SOR  TO LOVE S AND ME FOR SOMEIN BODY LIK ME  COME AND NOW FOLLOW MYLE A MAYBE GREAZE DON'T MIND ME SAFE BOY THAT'S O O TO BO A O OY SENT O TOT BODY ON ME  COME AND NOW FOLLOW MYMY OCOM AND NOW FOLLOW MYLYCOMIN OIT SY OY BU HAN B LIK A MAGNATO MY HAD  BOOWMI COM IN OI O BY\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber(\"/content/sample_audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LsjMDUNtKUfX"
   },
   "outputs": [],
   "source": [
    "transcriber = pipeline(model=\"openai/whisper-large-v2\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_iX1CI0Kult",
    "outputId": "f1518b3e-c527-4c69-8aec-c20dcf5a582d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': \" Talk slow, come over and start up a conversation with just me And trust me I'll give it a chance Now take my hand, stop and the man on the jukebox And then we start to dance and I'm singing like Girl you know I want your love Your love was handmade for somebody like me Come on now follow my lead I may be crazy, don't mind me Say boy, let's not talk too much Grab on my waist and put that body on me Come on now follow my lead Come, come and now follow my lead Mmm-hmm-hmm I'm in love with the shape of you We push and pull like a magnet do Although my heart is falling too I'm in love with your body\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber(\"/content/sample_audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7agHFV-PhPn",
    "outputId": "658c5bfb-a2a6-4415-ba84-155b58565770"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': \" Talk slow, come over and start up a conversation with just me And trust me I'll give it a chance Now take my hand, stop and the man on the jukebox And then we start to dance and I'm singing like Girl you know I want your love Your love was handmade for somebody like me Come on now follow my lead I may be crazy, don't mind me Say boy, let's not talk too much Grab on my waist and put that body on me Come on now follow my lead Come, come and now follow my lead Mmm-hmm-hmm I'm in love with the shape of you We push and pull like a magnet do Although my heart is falling too I'm in love with your body\",\n",
       " 'chunks': [{'timestamp': (0.0, 4.0),\n",
       "   'text': ' Talk slow, come over and start up a conversation with just me'},\n",
       "  {'timestamp': (4.0, 6.0), 'text': \" And trust me I'll give it a chance\"},\n",
       "  {'timestamp': (6.0, 9.0),\n",
       "   'text': ' Now take my hand, stop and the man on the jukebox'},\n",
       "  {'timestamp': (9.0, 11.5),\n",
       "   'text': \" And then we start to dance and I'm singing like\"},\n",
       "  {'timestamp': (11.5, 14.0), 'text': ' Girl you know I want your love'},\n",
       "  {'timestamp': (14.0, 17.0),\n",
       "   'text': ' Your love was handmade for somebody like me'},\n",
       "  {'timestamp': (17.0, 19.0), 'text': ' Come on now follow my lead'},\n",
       "  {'timestamp': (19.0, 21.0), 'text': \" I may be crazy, don't mind me\"},\n",
       "  {'timestamp': (21.0, 24.0), 'text': \" Say boy, let's not talk too much\"},\n",
       "  {'timestamp': (24.0, 27.0),\n",
       "   'text': ' Grab on my waist and put that body on me'},\n",
       "  {'timestamp': (27.0, 29.0), 'text': ' Come on now follow my lead'},\n",
       "  {'timestamp': (0.0, 2.0), 'text': ' Come, come and now follow my lead'},\n",
       "  {'timestamp': (2.0, 4.0), 'text': ' Mmm-hmm-hmm'},\n",
       "  {'timestamp': (4.0, 6.0), 'text': \" I'm in love with the shape of you\"},\n",
       "  {'timestamp': (6.0, 8.0), 'text': ' We push and pull like a magnet do'},\n",
       "  {'timestamp': (8.0, 10.0), 'text': ' Although my heart is falling too'},\n",
       "  {'timestamp': (10.0, 12.0), 'text': \" I'm in love with your body\"}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber = pipeline(model=\"openai/whisper-large-v2\", return_timestamps=True)\n",
    "transcriber(\"/content/sample_audio.mp3\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
